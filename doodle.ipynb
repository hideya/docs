{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 落書き認識Webアプリを作ろう\n",
    "\n",
    "- Author: Arata Furukawa ([github](https://github.com/ornew), [facebook](https://www.facebook.com/old.r.new))\n",
    "- Contributor: Hideya Kawahara ([github](https://github.com/hideya))\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、セミナーの資料として作成されています。ノートブックは、自由な編集、実行が可能です。Markdown形式でドキュメントも書き込めるため、必要に応じてメモを追記するなど、工夫してご利用ください。\n",
    "\n",
    "編集も含めて保存したい場合は、画面上部のツールバーから、【File】タブを選び、【Download as】を選ぶことでローカルマシン上に保存することが可能です。\n",
    "\n",
    "このノートブックは自由にご利用頂けますが、インターネット上への無断での転載だけはご遠慮くださいますようお願いします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハンズオンの概要\n",
    "\n",
    "Google が [\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data) として公開している多量の落書きの画像データを用いてニューラルネットワークを訓練し、何の落書きかを認識するニューラルネットを生成します。そしてその学習済みニューラルネットワークを組み込んだ、落書きの分類をする Web App を作成します。以下は、最終的な Web App のスクリーンショットです。実際のアプリは [ここをクリックすることで実行](https://tfjs-doodle-recognition-pwa.netlify.com/) できます。\n",
    "\n",
    "![](https://i.imgur.com/G6g18ap.png)\n",
    "\n",
    "ニューラルネットワークのモデルとしては、手書き数字（[MNIST](https://en.wikipedia.org/wiki/MNIST_database)）の認識で実績のある [Convolutional Neural Network (CNN) ](https://en.wikipedia.org/wiki/Convolutional_neural_network) を用います。\n",
    "\n",
    "モデルの構築と学習には、[AWS SageMaker](https://aws.amazon.com/jp/sagemaker/) 上で、\n",
    "[TensorFlow](https://www.tensorflow.org/) を使用します。\n",
    "\n",
    "Web App の構築には、JavaScript でニューラルネットワークの実装とブラウザ上での実行を可能とする [TensorFlow.js](https://js.tensorflow.org/) を利用します。\n",
    "\n",
    "以下に続くノートブックで、それぞれの過程を詳しく説明します（なお、ニューラルネットワークの学習を行う際、数十円の課金が発生します）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### ご参考：ノートブックの操作方法\n",
    "\n",
    "ノートブックは、自由な編集、実行が可能です。Markdown形式でドキュメントも書き込めるため、必要に応じてメモを追記するなど、工夫してご利用ください。\n",
    "\n",
    "以下に良く使うキー操作を列挙します：\n",
    "\n",
    "|キー操作| 説 明 | | キー操作 | 説 明 |\n",
    "|--|--| |--|--|\n",
    "| Enter | 編集モードに入る |　　　　| Esc → A | 新規セルを上に追加 | \n",
    "| Shift + Enter | セルを実行し / 編集モードから抜け、下のセルに移動 |　　　| Esc → B | 新規セルを下に追加 |\n",
    "| Cntl + Enter | セルを実行する / 編集モードから抜ける |    |Esc → D, D | セルを削除 |\n",
    "| Esc → M | セルをマークダウンモードに変更 |     | Esc → L | セルの行番号の表示・非表示 |\n",
    "| Esc → Y | セルをコードモードに変更 |      | Esc → H | キーボード・ショートカットの一覧の表示 |\n",
    "\n",
    "- ノートブックを初期状態に戻したい（全ての実行結果の消去とカーネルのリスタートをしたい）場合は、\n",
    "    画面上部のツールバーから **Kernel → Restart & Clear Output** を選択します。\n",
    "\n",
    "- 編集済みのノートブックをローカルにセーブしたい場合は、ツールバーから **File → Download as → Notebook**\n",
    "    を選択します。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回、認識する落書きは、以下の10クラス(種類)です。\n",
    "\n",
    "1. りんご (apple)\n",
    "2. ベッド (bed)\n",
    "3. 猫 (cat)\n",
    "4. 犬 (dog)\n",
    "5. 目 (eye)\n",
    "6. 魚 (fish)\n",
    "7. 草 (grass)\n",
    "8. 手 (hand)\n",
    "9. アイスクリーム (ice cream)\n",
    "10. ジャケット (jacket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28ピクセルのグレースケール画像から、上記のいずれの落書きであるかを**確率的に**予測します。\n",
    "\n",
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープラーニング\n",
    "\n",
    "モデルは(ディープ)ニューラルネットワークで実装します。\n",
    "\n",
    "ニューラルネットワークとは、生物のニューロン(神経細胞)のネットワークを数理モデルで模倣することで、特定の課題解決能力を機械的に学習する、機械学習アルゴリズムの一種です。深い層で構成されるニューラルネットワークの学習を行うことをディープラーニングといいます。\n",
    "\n",
    "ディープラーニングにおけるモデルの学習は、以下の流れで行います。\n",
    "\n",
    "- ⓪ モデルのパラメータを初期化する\n",
    "- ① 学習用データに対する予測を計算する\n",
    "- ② 教師ラベルと予測結果の誤差を計算する\n",
    "- ③ 誤差を最小化するようにモデルのパラメータを更新する\n",
    "- ④ **誤差が十分に小さくなるまで**①-③を繰り返す\n",
    "\n",
    "![](./img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装の流れ\n",
    "\n",
    "このノートブックでは、以下の手順で、ディープラーニングを用いた落書き(Doodle)認識を行うWebアプリを作成します。\n",
    "\n",
    "1. [\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を学習用データとして準備する\n",
    "2. [TensorFlow](https://www.tensorflow.org/)で落書きを認識するディープニューラルネットワークのモデルを実装する\n",
    "3. [Amazon SageMaker](https://aws.amazon.com/jp/sagemaker/)でモデルを学習する\n",
    "4. [TensorFlow.js](https://js.tensorflow.org/)を使ったWebアプリに学習済みモデルを組み込む\n",
    "5. [Amazon S3](https://aws.amazon.com/jp/s3/)でWebアプリを公開する\n",
    "\n",
    "![](./img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、作業に必要な Python のモジュールをノートブック・インスタンスに読み込みます。\n",
    "\n",
    "実行ログの出力が始まるまで、少々（30秒程度）時間がかかりますので、しばらく反応がなくてもすこし様子を見てください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import six         # Python 2と3の互換性を保つためのライブラリです\n",
    "import numpy as np # 行列などの科学数値計算をするためのライブラリです\n",
    "\n",
    "import matplotlib.pyplot as plt # グラフを描画するライブラリです\n",
    "%matplotlib inline\n",
    "\n",
    "# 繰り返し処理の進捗をプログレスバーで表示するためのライブラリです\n",
    "!pip install tqdm msgpack\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 学習用データを準備する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データは、Google社が[クリエイティブ・コモンズ ライセンス バージョン4.0](https://creativecommons.org/licenses/by/4.0/)で公開している[\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データをダウンロードする\n",
    "\n",
    "データをダウンロードして、`./raw_data`ディレクトリに保存します。\n",
    "\n",
    "ちなみに、Jupyterノートブックでは、「`!`」を先頭につけると、シェルコマンドを実行できます(Pythonの機能ではありません)。出力をPythonで使ったり、Pythonの変数を引数に使ったりも出来るので便利です。ここでは`wget`コマンドを使ってファイルをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap'\n",
    "LABELS = [\n",
    "    'apple', 'bed', 'cat', 'dog', 'eye',\n",
    "    'fish', 'grass', 'hand', 'ice cream', 'jacket',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data ./raw_data\n",
    "!mkdir -p ./data ./raw_data\n",
    "for l in LABELS:\n",
    "    url = '{}/{}.npy'.format(URL, l)\n",
    "    !wget -P raw_data \"$url\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ラベルのデータファイルがダウンロードできていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ./raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータを配列 (numpy.ndarray) に読み込みます。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {label: np.load('raw_data/{}.npy'.format(label)) for label in tqdm(LABELS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各データの数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in six.iteritems(raw_data):\n",
    "    print('{:10}: {}'.format(label, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ためしに、1番目の「猫」の画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(raw_data['cat'][0], [28, 28]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習用と評価用のデータを準備する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、データを学習用と評価用に分けます。\n",
    "\n",
    "学習に使ったデータは、モデルがすでに「知っている」データなので、そのモデルが本当に役に立つのかを評価するためには学習に使っていない「未知のデータ」に対する精度を確認する必要があります。ですので、ダウンロードしたデータから、学習用と評価用の2種類のデータを予め準備します。\n",
    "\n",
    "1. ダウンロードしたデータセットのうち1万件を取り出す *1\n",
    "    - クラスごとに数にばらつきがあると、学習で用いられる頻度がクラスごとに変わってしまうため、揃えます\n",
    "2. それぞれ画像データと教師ラベルの組み合わせに変換する\n",
    "    - 教師ラベルは、クラスの名前(例:apple)ではなく、それぞれクラスごとにユニークな数字を割り当てます(下で確認)\n",
    "3. 学習用と評価用に7:3で分ける\n",
    "    - 学習に使われていないデータで精度の評価を行いたいため、3割を評価用のデータとして使います\n",
    "4. ランダムにシャッフル\n",
    "\n",
    "    *1 … もとは「10万」だったのですが、時間単価の安い（初期無料枠のある）「t2.medium」ノートブック・インスタンスで\n",
    "    メモリ不足を起こさず扱えるように少なくしています。\n",
    "    結果として、認識の精度（描画のブレへの対応力）は少々下がります。\n",
    "    （SageMaker の料金一覧は[こちら](https://aws.amazon.com/jp/sagemaker/pricing/)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に先立って、画像の各クラスを出力ニューロンと対応づけます。\n",
    "ニューラルネットワーク (CNN) の認識結果は、各出力ニューロンの状態（０から１の値）により得られます。\n",
    "そのため、それぞれの出力ニューロンを、判定するクラスと１対１に対応づけます。\n",
    "つまり、10個の出力ニューロンを用意し、そのn番目のニューロンを、n番目のクラスと対応づけます。\n",
    "ここでは、ラベル配列のインデクスをそのまま両者を対応付ける序数として使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label_name in enumerate(LABELS):\n",
    "    print(u'出力ニューロン　番号: {}   クラス名: {}'.format(i, label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、データを前処理して、ニューラルネットワークの訓練に用いるのに適した形式に変換します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、メモリ不足を起こさないように、また学習スピードを上げるために、最初にデータの個数を1万に削減します。\n",
    "もともとは「10万」個のデータを使用していたのですが、\n",
    "無料枠のある「t2.medium」ノートブック・インスタンスで処理をしてもメモリ不足を起こさないようにするために、\n",
    "１万個に削減しています。 またこれにより、学習時間が短縮できます。\n",
    "結果として、認識の精度（描画のブレへの対応力）は少々下がります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in six.iteritems(raw_data):\n",
    "    raw_data[label] = raw_data[label][:10000]\n",
    "\n",
    "for label, data in six.iteritems(raw_data):\n",
    "    print('{:10}: {}'.format(label, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ピクセルの値が0から1に収まるように正規化し、学習用と評価用のデータに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for label_name, value in six.iteritems(raw_data):\n",
    "    label_index = LABELS.index(label_name)\n",
    "    print('proccessing label class {}: \"{}\"'.format(label_index, label_name))\n",
    "    # 各ピクセルの値を、0-255から0-1に修正します\n",
    "    value = np.asarray(value) / 255.\n",
    "    # 7万件を学習用のデータとして画像データと教師ラベルの組み合わせにしてリストに追加します\n",
    "    train_data.extend(zip(value[:7000], np.full(7000, label_index)))\n",
    "    # 3万件を評価用のデータとして画像データと教師ラベルの組み合わせにしてリストに追加します\n",
    "    test_data.extend(zip(value[7000:10000], np.full(3000, label_index)))\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、これら学習用と評価用のデータを、ニューラルネットワークの訓練での利用に適した\n",
    "TFRecord 形式のファイルに変換して出力します。\n",
    "TFRecord は [Protocol Buffers](https://developers.google.com/protocol-buffers/) というフォーマットを用いたデータファイルで、構造化されている・圧縮効率が高い・読み書きの速度が非常に速い・非同期のストリーミング読み込みが可能\n",
    "とった長所があり、機械学習で用いられる大規模データセットの保存に向いています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、ヘルパー関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = './data/train.tfr'\n",
    "test_filename  = './data/test.tfr'\n",
    "\n",
    "def get_example_proto(image, label):\n",
    "    \"\"\"\n",
    "    画像とラベルをProtocol Buffers形式のtf.train.Exampleに変換します\n",
    "    \"\"\"\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image' : tf.train.Feature(float_list=tf.train.FloatList(value=image)),\n",
    "        'label' : tf.train.Feature(int64_list=tf.train.Int64List(value=label)),\n",
    "    })).SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の変換処理は30秒ほどかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfr_options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "with tf.python_io.TFRecordWriter(train_filename, tfr_options) as train_tfr, \\\n",
    "     tf.python_io.TFRecordWriter(test_filename, tfr_options) as test_tfr:\n",
    "    print('Converting train data...')\n",
    "    for data, label in tqdm(train_data):\n",
    "        train_tfr.write(get_example_proto(data, [label]))\n",
    "    print('Converting test data...')\n",
    "    for data, label in tqdm(test_data):\n",
    "        test_tfr.write(get_example_proto(data, [label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.tfr`と`test.tfr`が生成されていれば成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、データの準備が完了しました。\n",
    "\n",
    "生成したデータは、学習モデルの設定を終えた後、学習プロセスを開始する前に、\n",
    "S3 にアップロードして、学習用インスタンスからアクセスできるようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② TensorFlowでモデルの定義プログラムを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの実装には、[TensorFlow](https://www.tensorflow.org/)を利用します。TensorFlowは、Google社が主体となって開発している、オープンソースの汎用的な分散数値演算ライブラリです。TensorFlowにはディープラーニング向けのライブラリが用意されています。GitHubのスターは10万近くあり、現在世界で最も人気のディープラーニングフレームワークとも言われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の4つの関数を定義したプログラムを用意すると、Amazon SageMakerを使ってモデルの学習を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train_input_fn(training_dir, hyperparameters):\n",
    "    \"\"\"\n",
    "    学習用の入力データを読み込みます。\n",
    "    \n",
    "        training_dir: 学習の実行時に指定したS3のファイルがこの文字列のディレクトリにマウントされています。\n",
    "        hyperparameters: 学習の実行時に指定したハイパーパラメータが渡されます。\n",
    "        \n",
    "    基本的には、以下のことを実装するだけです。\n",
    "    ① hyperparametersで指定した挙動に従って、\n",
    "    ② training_dirから学習データを読み込み、データを返す。\n",
    "    \"\"\"\n",
    "\n",
    "def eval_input_fn(training_dir, hyperparameters):\n",
    "    \"\"\"\n",
    "    評価用の入力データを読み込みます。\n",
    "    やることはtrain_input_fnと同じですが、評価用のデータを読み込むことや、\n",
    "    評価用に挙動を変える(例えば評価データはシャッフルしないなど)ことが可能です。\n",
    "    \"\"\"\n",
    "\n",
    "def serving_input_fn(hyperparameters):\n",
    "    \"\"\"\n",
    "    モデルの入力データの形式を定義します。\n",
    "    サービングと付いている通り、SageMakerでAPIサーバにデプロイしたときの入力データ定義にもなります。\n",
    "    \"\"\"\n",
    "\n",
    "def model_fn(features, labels, mode, hyperparameters):\n",
    "    \"\"\"\n",
    "    モデルの定義をします\n",
    "    \n",
    "        features: モデルの入力と成る特徴データです *_input_fnで返した値がそのまま渡されます。\n",
    "        labels: モデルの教師ラベルデータです。\n",
    "        mode: モデルの実行モードです。実行モードには「学習」「評価」「推論」があり、挙動を切り替えることが可能です。\n",
    "        hyperparameters: 実行時に指定したハイパーパラメータが渡されます。\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後の`model_fn`が、その名のとおり、ニューラルネットワークの定義の本体です。\n",
    "\n",
    "`model_fn`の中では、以下の3つを定義します。\n",
    "\n",
    "1. **モデル**: ニューラルネットワーク\n",
    "2. **誤差**: 教師データと予測結果がどの程度違ったのかを定式化する\n",
    "3. **最適化アルゴリズム**: 誤差を最小化するようにモデルを最適化するアルゴリズム\n",
    "\n",
    "つまり、データの入力方法と、上記3つのモデル関連の定義を行うだけで、機械学習を行うことができてしまいます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回、セミナー用のモデル定義は予め実装してあります(`src/doodle.py`ファイル)。\n",
    "\n",
    "以下を実行して、その内容を確認してみましょう。\n",
    "コメントなどを含めても200行弱程度しかありません。\n",
    "コードには多くのコメントが付けてありますので、ざっと目を通してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat src/doodle.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークのモデルの定義や学習に関する詳細は、別途ノートブック`model.ipynb`で解説しています。ニューラルネットワークの実装に興味がある方はそちらをご参照ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ Amazon SageMakerでモデルを学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker SDKを使い、ここまでで準備したデータとプログラムを指定して学習を実行します。\n",
    "\n",
    "![](img/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 設定情報を定義する\n",
    "\n",
    "モデルの学習を始めるにあたり、学習に使用するデータの保存先などの設定情報を変数で定義します。\n",
    "ここで、学習ジョブの名前を定義しますので、もし再度、学習を繰り返したい場合には、ここから以下を再実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from datetime import datetime\n",
    "import six\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "def _s3(path):\n",
    "    return 's3://{}/doodle-{}/model/{}'.format(bucket, timestamp, path)\n",
    "\n",
    "data_key_prefix =  'doodle-{}/model/data'.format(timestamp)\n",
    "\n",
    "config = dict(\n",
    "    data_dir        = _s3('data'),\n",
    "    output_path     = _s3('export'),\n",
    "    checkpoint_path = _s3('ckpt'),\n",
    "    code_location   = _s3('src'),\n",
    "    public_dir      = _s3('public'),\n",
    "    job_name        = 'doodle-training-job-{}'.format(timestamp)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認のため、設定した変数を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in six.iteritems(config):\n",
    "    print('key: {:20}, value: {:20}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 にデータをアップロードする\n",
    "\n",
    "上記で設定した S3 パスに、①で作成したデータセットをアップロードし、学習インスタンスが学習データにアクセスできるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_data_dir = session.upload_data(\n",
    "    'data',                     # ローカルディレクトリ\n",
    "    bucket=bucket,    # アップロードするS3バケット名\n",
    "    key_prefix=data_key_prefix) # アップロードするパスのプリフィクス\n",
    "\n",
    "# 設定と同じ場所になったか念のため確認します\n",
    "assert uploaded_data_dir == config['data_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、学習用と評価用のデータの準備がおわりました。\n",
    "次に、学習を行うモデルを構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの学習では、「エスティメータ(Estimator)」を利用します。 エスティメータとは、モデルの学習や評価、保存やデプロイといった一連の処理を簡便に行うための、高レベルのインターフェイスです。\n",
    "\n",
    "用意したパスなどを設定として渡して、エスティメータを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エスティメータへのパラメータとして、`entry_point`に`doodle.py`が指定されていることに注目してください。\n",
    "この Python のプログラム`doodle.py`で、②で述べた、ニューラルネットワークのモデルやそれに関わるシステムの挙動が定義されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    # ハイパーパラメータ\n",
    "    # ②で定義したプログラムの各関数の引数に渡されます\n",
    "    # プログラムの挙動を切り替えるのに利用できます\n",
    "    hyperparameters={\n",
    "        'save_summary_steps': 100,\n",
    "        'throttle_secs': 120,\n",
    "    },\n",
    "    \n",
    "    # 先程設定した、各データの保存先のパス\n",
    "    output_path     = config['output_path'],\n",
    "    checkpoint_path = config['checkpoint_path'],\n",
    "    code_location   = config['code_location'],\n",
    "    \n",
    "    # 学習用プログラムに関する設定\n",
    "    source_dir='./src',      # 学習用のプログラムが保存されたローカルディレクトリ\n",
    "    entry_point='doodle.py', # ②で定義した学習用プログラムのファイル名\n",
    "    framework_version='1.6', # 利用したいTensorFlowのバージョン\n",
    "    \n",
    "    # 学習と評価の回数\n",
    "    training_steps=10000,\n",
    "    evaluation_steps=1000,\n",
    "    \n",
    "    # AWSでの実行に関する設定\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge') # ml.p2.xlargeはGPUの搭載されたインスタンスです"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このエスティメータに対して、学習用データのパス名を指定して`fit`関数を呼び出すと、学習ジョブが作成され、クラウド上でモデルの学習を実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この学習には10分弱かかります。\n",
    "その間、学習中の状態を確認するために、ノートブック上で\n",
    "[TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)\n",
    "を起動します\n",
    "（そのために`run_tensorboard_locally`引数に`True`を渡します）。\n",
    "\n",
    "なお、この学習では、１回で、数十円の課金が発生します\n",
    "（ご参考：「[Amazon SageMaker の料金](https://aws.amazon.com/jp/sagemaker/pricing/)」）。\n",
    "\n",
    "それでは、以下のセルで、学習をスタートしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(config['data_dir'], job_name=config['job_name'],\n",
    "              wait=True, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ノートブック上で実行される TensorBoard は、学習経過を表示するように設定してあります。\n",
    "\n",
    "[ここをクリックすることにより](/proxy/6006/)、TensorBoard の画面がブラウザで開き、学習経過が確認できます\n",
    "（実行ログ中に表示される`http://localhost:6006`ではアクセスできません。\n",
    "`https://(ノートブックのURL)/`[proxy/6006/](/proxy/6006/) にアクセスする必要があります）。\n",
    "\n",
    "学習のセットアップをしている最初のうちは「No dashboards are active for the current data set」とだけ表示されますが、\n",
    "４〜５分経って、上のセルにログが出力され始めると、学習経過を示すグラフが表示されるようになります。\n",
    "ログが表示されはじめるのを待ってから、TensorBoard のページを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の学習ジョブが終了したら、学習したモデルをチェックしてみましょう。\n",
    "\n",
    "学習済みモデルのファイルは、エスティメータのoutput_path引数で指定した場所に保存されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_url = '{}/{}/output/'.format(config['output_path'], config['job_name'])\n",
    "!echo $output_dir_url\n",
    "!aws s3 ls $output_dir_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④ 学習したモデルをダウンロードして、Webアプリに組み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルは、エスティメータの`output_path`引数で指定した場所にGZIP圧縮されたTarアーカイブとして保存されています。中身はTesnorFlow SavedModelと呼ばれるデータ形式です。\n",
    "\n",
    "![](img/5.png)\n",
    "\n",
    "このモデルデータを使えば、Pythonで実行したり、TensorFlow ServingでAPIサーバを構築したり、TensorFlow Liteを使ってAndroidやiOSで実行したりすることが可能です。\n",
    "\n",
    "今回は、TensorFlow.jsを使って、Webブラウザ上でモデルの推論を実行してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、学習済みモデルデータをS3からノートブック・インスタンスにダウンロードして解凍します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = '{}/{}/output/model.tar.gz'.format(config['output_path'], config['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./export ./model.tar.gz\n",
    "!aws s3 cp \"$model_url\" ./model.tar.gz\n",
    "!tar xvzf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、TensorFlow.js で読み込め、推論が実行できる形式に、学習済みモデルデータのフォーマットを変更します。\n",
    "\n",
    "そために、変換用ツールをインストールし、これを上で解凍したモデルデータに対して適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換用ツールをインストールします\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換したモデルの保存先ディレクトリを作成します\n",
    "!rm -rf ./webapp\n",
    "!mkdir -p ./webapp/model\n",
    "\n",
    "# 変換ツールを実行します\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    --output_node_names='probabilities,classes' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    ./export/Servo/* \\\n",
    "    ./webapp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、`./webapp/model`ディレクトリにTensorFlow.jsで読み込めるモデルデータが生成されました！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ./webapp/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このモデルデータを TensorFlow.js で読み込み、推論を実行します。\n",
    "\n",
    "以下に、読み込みおよび推論実行コードの主要部をあげます：\n",
    "\n",
    "```javascript\n",
    "// ライブラリを読み込みます\n",
    "import * as tf from '@tensorflow/tfjs-core';\n",
    "import {loadFrozenModel} from '@tensorflow/tfjs-converter';\n",
    "...\n",
    "// モデルを読み込みます\n",
    "const model = await loadFrozenModel(modelUrl, weightsUrl);\n",
    "...\n",
    "// モデルで推論を実行し、結果を獲得します\n",
    "const output = model.execute({'image_1': input/* 画像データ */}, 'probabilities');\n",
    "const probabilities = output.dataSync();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非常に簡単です！\n",
    "とはいえ実際には、諸設定を行ったりアプリケーションとしての体裁を整えたりする「ガワ」を作らねばなりません。\n",
    "その詳細な説明は、ここでは割愛します。\n",
    "その代わり、既に用意されている、モデルデータを簡単に組み込めるWebアプリケーションのテスト用コードに、\n",
    "学習済みのモデルデータを組み込んで実行することにより、データの検証をしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、作成済みのWebアプリケーションのZIPをダウンロードして展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O webapp.zip https://github.com/hideya/tfjs-doodle-recognition-pwa/releases/download/0.0.3/nonpwa-webapp.zip\n",
    "!unzip webapp.zip -d webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、`webapp`ディレクトリ以下にWebアプリケーションに必要なものが全て揃いました！\n",
    "\n",
    "確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -Rl ./webapp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、このWebアプリケーションのソースコードは\n",
    "[https://github.com/hideya/tfjs-doodle-recognition-pwa/tree/simple](https://github.com/hideya/tfjs-doodle-recognition-pwa/tree/simple)\n",
    "にて公開しています（simpleブランチです。masterブランチはsimpleバージョンを [PWA](https://developers.google.com/web/progressive-web-apps/) 化したものになります）。\n",
    "\n",
    "また、[Vue.js](https://vuejs.org/) を用いたプログラムサンプルも [maru-labo/doodle/examples/tensorflow_js](https://github.com/maru-labo/doodle/tree/master/examples/tensorflow_js) にて公開しています。ぜひ参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤ WebアプリをS3でホスティングして公開する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`webapp`ディレクトリに必要なものが揃ったので、Web上に公開してみましょう。S3の静的ホスティング機能を使うと簡単にWebアプリケーションを公開できます。`aws s3 sync`コマンドで`webapp`ディレクトリを`public_dir`変数に格納したURLにアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_dir = config['public_dir']\n",
    "!aws s3 sync ./webapp $public_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで必要なファイルが S3 にアップロードされました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアプリを公開し、ブラウザからアクセスできるようにするためには、ファイルが格納された S3 のバケットの「Access」を「Public」にする必要があります（必要なファイルのみをPublicにする方法もあるのですが、今回は簡便のためバケット全体をPublicに設定します）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのためには、まず、下記セルを実行して表示される URL をクリックして、学習結果が格納されたバケットを開きます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://s3.console.aws.amazon.com/s3/buckets/{}'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず「プロパティ Properties」タブを開き、「Static website hosting」を選択し、さらに「このバケットを使用してウェブサイトをホストする Use this bucket to host a website」を選択します。\n",
    "「インデックスドキュメント Index document」には「index.html」と書き込みます。その他は空欄のままでOKです。\n",
    "「保存 Save」をクリックします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、もう一つ、設定が必要です。\n",
    "\n",
    "「アクセス権限 Permissions」タブを開きます。\n",
    "次に、タブのすぐ下に表示されるメニューから「バケットポリシー Buket Policy」を選択します。\n",
    "\n",
    "「バケットポリシーエディター Bucket policy editor」が開いたら、以下のテキストをコピペし、くわえて、「sagemaker-us-west-2-000000000000」の部分を、\n",
    "今対象としているバケット名に合うように書き換えます。\n",
    "「保存 Save」をクリックします。\n",
    "\n",
    "「このバケットにはパブリックアクセス権限があります This bucket has public access」と警告が表示され、「バケットポリシー Buket Policy」の下に「パブリック Public」と表示されれば完了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "     {\n",
    "    \"Sid\": \"PublicReadGetObject\",\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Principal\": \"*\",\n",
    "    \"Action\": \"s3:GetObject\",\n",
    "    \"Resource\": \"arn:aws:s3:::sagemaker-us-west-2-000000000000/*\"\n",
    "     }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、S3 バケットの設定は完了です。これで、アップロードされたWebアプリケーションがブラウザからアクセスできるようになりました。\n",
    "\n",
    "それでは早速、アップロードされたWebアプリケーションの動作を確認してみましょう！\n",
    "\n",
    "下記セルを実行するとURLが表示されますので、クリックして開いてみてください。\n",
    "大きなモデルデータを読み込む必要があるため、起動に少々時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://s3-{}.amazonaws.com/{}/index.html'.format(session.boto_region_name, public_dir[5:]))\n",
    "\n",
    "print('\\nもし上のURLで「Error PermanentRedirect」が発生してうまく表示されない場合は、下のURLを試してみてください。')\n",
    "print('https://s3.amazonaws.com/{}/index.html'.format(public_dir[5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本ノートブック冒頭のスクリーンショットのようなアプリが、ちゃんと表示されましたでしょうか？\n",
    "落書きの認識精度はいかがでしょうか？\n",
    "\n",
    "これで、本ハンズオンは終了です。おつかれさまでした。\n",
    "\n",
    "認識率の改善を目指して学習データの数を増やしたり、学習パラメータを変更したり、いろいろ実験してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 後始末\n",
    "\n",
    "実験の後、インスタンスを動いたままにしていたり、巨大なデータを放置していると、思わぬ課金が発生することがあります。\n",
    "\n",
    "実験がひととおり終わったら、以下の後始末をすることをおすすめします：\n",
    "\n",
    "- ノートブックを閉じたら、ノートブック・インスタンスを停止する（これは忘れやすいので気をつけてください）。\n",
    "- 実験等で多量に溜まったデータファイルのうち不要なものは、S3 やノートブックインスタンスから削除する。\n",
    "- Public になっている S3 の設定を Private にもどす（外部からの意図しないアクセスによるデータ送信の課金を避ける）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課金の状態は、「Billing & Cost Management Dashboard」で簡単に確認することができます。\n",
    "\n",
    "こちらのURL https://console.aws.amazon.com/billing/home をクリックして、確認してみてください\n",
    "（前日までの利用料が表示されますので、今日の分を知りたい場合は、翌日まで待ってからチェックしてみてください）。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "- ✔ 簡単なデータセットを作りました\n",
    "- ✔ SageMakerでモデルを学習しました\n",
    "- ✔ SageMakerで学習したモデルをWebアプリケーションで実行しました\n",
    "\n",
    "なお、落書き認識モデルについては、本日使用したサンプルを含めて全て[GitHub](https://github.com/maru-labo/doodle)上で公開していますので、より詳しい情報をご希望の方はぜひご参照ください。今後、LiteのサンプルやServingの使い方などもリポジトリに追加する予定です。MITライセンスですので、ご自由にご利用いただけます。お気軽にIssueやPull Requestをお寄せくださいませ。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
