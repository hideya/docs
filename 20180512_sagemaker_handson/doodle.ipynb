{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 落書き認識Webアプリを作ろう\n",
    "\n",
    "- Author: Arata Furukawa ([github](https://github.com/ornew), [facebook](https://www.facebook.com/old.r.new))\n",
    "- Contributor: Hideya Kawahara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、セミナーの資料として作成されています。ノートブックは、自由な編集、実行が可能です。Markdown形式でドキュメントも書き込めるため、必要に応じてメモを追記するなど、工夫してご利用ください。\n",
    "\n",
    "参加者の皆様には後日データを配布いたしますが、編集も含めて持ち帰りたい場合は、画面上部のツールバーから、【File】タブを選び、【Download as】を選ぶことでローカルマシン上に保存することが可能です。\n",
    "\n",
    "このノートブックはご自由にご利用頂けますが、インターネット上への無断での転載だけはご遠慮くださいますようお願いします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回、認識する落書きは、以下の10クラス(種類)です。\n",
    "\n",
    "1. りんご(apple)\n",
    "2. ベッド(bed)\n",
    "3. 猫(cat)\n",
    "4. 犬(dog)\n",
    "5. 目(eye)\n",
    "6. 魚(fish)\n",
    "7. 草(grass)\n",
    "8. 手(hand)\n",
    "9. アイスクリーム(ice cream)\n",
    "10. ジャケット(jacket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28ピクセルのグレースケール画像から、上記のいずれの落書きであるかを**確率的に**予測します。\n",
    "\n",
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープラーニング\n",
    "\n",
    "モデルは(ディープ)ニューラルネットワークで実装します。\n",
    "\n",
    "ニューラルネットワークとは、生物のニューロン(神経細胞)のネットワークを数理モデルで模倣することで、特定の課題解決能力を機械的に学習する、機械学習アルゴリズムの一種です。深い層で構成されるニューラルネットワークの学習を行うことをディープラーニングといいます。\n",
    "\n",
    "ディープラーニングにおけるモデルの学習は、以下の流れで行います。\n",
    "\n",
    "- ⓪ モデルのパラメータを初期化する\n",
    "- ① 学習用データに対する予測を計算する\n",
    "- ② 教師ラベルと予測結果の誤差を計算する\n",
    "- ③ 誤差を最小化するようにモデルのパラメータを更新する\n",
    "- ④ **誤差が十分に小さくなるまで**①-③を繰り返す\n",
    "\n",
    "![](./img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装の流れ\n",
    "\n",
    "このノートブックでは、以下の手順で、ディープラーニングを用いた落書き(Doodle)認識を行うWebアプリを作成します。\n",
    "\n",
    "1. [\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を学習用データとして準備する\n",
    "2. [TensorFlow](https://www.tensorflow.org/)で落書きを認識するディープニューラルネットワークのモデルを実装する\n",
    "3. [Amazon SageMaker](https://aws.amazon.com/jp/sagemaker/)でモデルを学習する\n",
    "4. [TensorFlow.js](https://js.tensorflow.org/)を使ったWebアプリに学習済みモデルを組み込む\n",
    "5. [Amazon S3](https://aws.amazon.com/jp/s3/)でWebアプリを公開する\n",
    "\n",
    "![](./img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、作業に必要なモジュールを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six         # Python 2と3の互換性を保つためのライブラリです\n",
    "import numpy as np # 行列などの科学数値計算をするためのライブラリです\n",
    "\n",
    "import matplotlib.pyplot as plt # グラフを描画するライブラリです\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ①学習用データを準備する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データは、Google社が[クリエイティブ・コモンズ ライセンス バージョン4.0](https://creativecommons.org/licenses/by/4.0/)で公開している[\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データをダウンロードする\n",
    "\n",
    "データをダウンロードして、`./raw_data`ディレクトリに保存します。\n",
    "\n",
    "ちなみに、Jupyterノートブックでは、「`!`」を先頭につけると、シェルコマンドを実行できます(Pythonの機能ではありません)。出力をPythonで使ったり、Pythonの変数を引数に使ったりも出来るので便利です。ここでは`wget`コマンドを使ってファイルをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap'\n",
    "LABELS = [\n",
    "    'apple', 'bed', 'cat', 'dog', 'eye',\n",
    "    'fish', 'grass', 'hand', 'ice cream', 'jacket',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data ./raw_data\n",
    "for l in LABELS:\n",
    "    url = '{}/{}.npy'.format(URL, l)\n",
    "    !wget -NP raw_data \"$url\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ラベルのデータファイルがダウンロードできていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {label: np.load('raw_data/{}.npy'.format(label)) for label in LABELS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各データの数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in six.iteritems(raw_data):\n",
    "    print('{:10}: {}'.format(label, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ためしに「猫」の画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(raw_data['cat'][0], [28, 28]), cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習用と評価用のデータを準備する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、データを学習用と評価用に分けます。\n",
    "\n",
    "学習に使ったデータは、モデルがすでに「知っている」データなので、そのモデルが本当に役に立つのかを評価するためには学習に使っていない「未知のデータ」に対する精度を確認する必要があります。ですので、ダウンロードしたデータから、学習用と評価用の2種類のデータを予め準備します。\n",
    "\n",
    "1. ダウンロードしたデータセットのうち10万件を取り出す\n",
    "    - クラスごとに数にばらつきがあると、学習で用いられる頻度がクラスごとに変わってしまうため、揃えます\n",
    "2. それぞれ画像データと教師ラベルの組み合わせに変換する\n",
    "    - 教師ラベルは、クラスの名前(例:apple)ではなく、それぞれクラスごとにユニークな数字を割り当てます(下で確認)\n",
    "3. 学習用と評価用に7:3で分ける\n",
    "    - 学習に使われていないデータで精度の評価を行いたいため、3割を評価用のデータとして使います\n",
    "4. ランダムにシャッフル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスごとに割り当てる教師ラベルの番号を確認します。今回は最初のラベル配列のインデクスをそのまま使います。数字自体に意味はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label_name in enumerate(LABELS):\n",
    "    print(u'番号: {}   ラベル名: {}'.format(i, label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for label_name, value in six.iteritems(raw_data):\n",
    "    label_index = LABELS.index(label_name)\n",
    "    print('proccessing label class {}: \"{}\"'.format(label_index, label_name))\n",
    "    # 各ピクセルの値を、0-255から0-1に修正します\n",
    "    value = np.asarray(value) / 255.\n",
    "    # 7万件を学習用のデータとして画像データと教師ラベルの組み合わせにしてリストに追加します\n",
    "    train_data.extend(zip(value[:70000], np.full(70000, label_index)))\n",
    "    # 3万件を評価用のデータとして画像データと教師ラベルの組み合わせにしてリストに追加します\n",
    "    test_data.extend(zip(value[70000:100000], np.full(30000, label_index)))\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用と評価用のデータを、TFRecord形式のファイルに出力します。TFRecordは[Protocol Buffers](https://developers.google.com/protocol-buffers/)というフォーマットを用いたデータファイルです。構造化されたデータであり、圧縮効率が高くと読み書きの速度が非常に速いデータ形式です、非同期のストリーミング読み込みが可能なため、機械学習で用いられる大規模データセットの保存に向いています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = './data/train.tfr'\n",
    "test_filename  = './data/test.tfr'\n",
    "\n",
    "def get_example_proto(image, label):\n",
    "    \"\"\"\n",
    "    画像とラベルをProtocol Buffers形式のtf.train.Exampleに変換します\n",
    "    \"\"\"\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image' : tf.train.Feature(float_list=tf.train.FloatList(value=image)),\n",
    "        'label' : tf.train.Feature(int64_list=tf.train.Int64List(value=label)),\n",
    "    })).SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の変換処理は5分ほどかかります。少々お待ちください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfr_options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "with tf.python_io.TFRecordWriter(train_filename, tfr_options) as train_tfr, \\\n",
    "     tf.python_io.TFRecordWriter(test_filename, tfr_options) as test_tfr:\n",
    "    print('Converting train data...')\n",
    "    for data, label in train_data:\n",
    "        train_tfr.write(get_example_proto(data, [label]))\n",
    "    print('Converting test data...')\n",
    "    for data, label in test_data:\n",
    "        test_tfr.write(get_example_proto(data, [label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.tfr`と`test.tfr`が生成されていれば成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの準備が完了しました。生成したデータは後ほどS3にアップロードします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ②TensorFlowでモデルの定義プログラムを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの実装には、[TensorFlow](https://www.tensorflow.org/)を利用します。TensorFlowは、Google社を主体として開発されている、オープンソースの汎用的な分散数値演算ライブラリです。TensorFlowにはディープラーニング向けのライブラリが用意されており、GitHubのスターは10万近く、現在世界で最も人気のディープラーニングフレームワークとも言われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の4つの関数を定義したプログラムを用意すると、Amazon SageMakerを使ってモデルの学習を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train_input_fn(training_dir, hyperparameters):\n",
    "    \"\"\"\n",
    "    学習用の入力データを読み込みます。\n",
    "    \n",
    "        training_dir: 学習の実行時に指定したS3のファイルがこの文字列のディレクトリにマウントされています。\n",
    "        hyperparameters: 学習の実行時に指定したハイパーパラメータが渡されます。\n",
    "        \n",
    "    基本的には、以下のことを実装するだけです。\n",
    "    ①hyperparametersで指定した挙動に従って、\n",
    "    ②training_dirから学習データを読み込み、データを返す。\n",
    "    \"\"\"\n",
    "\n",
    "def eval_input_fn(training_dir, hyperparameters):\n",
    "    \"\"\"\n",
    "    評価用の入力データを読み込みます。\n",
    "    やることはtrain_input_fnと同じですが、評価用のデータを読み込むことや、\n",
    "    評価用に挙動を変える(例えば評価データはシャッフルしないなど)ことが可能です。\n",
    "    \"\"\"\n",
    "\n",
    "def serving_input_fn(hyperparameters):\n",
    "    \"\"\"\n",
    "    モデルの入力データの形式を定義します。\n",
    "    サービングと付いている通り、SageMakerでAPIサーバにデプロイしたときの入力データ定義にもなります。\n",
    "    \"\"\"\n",
    "\n",
    "def model_fn(features, labels, mode, hyperparameters):\n",
    "    \"\"\"\n",
    "    モデルの定義をします\n",
    "    \n",
    "        features: モデルの入力と成る特徴データです *_input_fnで返した値がそのまま渡されます。\n",
    "        labels: モデルの教師ラベルデータです。\n",
    "        mode: モデルの実行モードです。実行モードには「学習」「評価」「推論」があり、挙動を切り替えることが可能です。\n",
    "        hyperparameters: 実行時に指定したハイパーパラメータが渡されます。\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう少し具体的には、`model_fn`の中で以下の3つを定義します。\n",
    "\n",
    "1. **モデル**: ニューラルネットワーク\n",
    "2. **誤差**: 教師データと予測結果がどの程度違ったのかを定式化する\n",
    "3. **最適化アルゴリズム**: 誤差を最小化するようにモデルを最適化するアルゴリズム\n",
    "\n",
    "つまり、データの入力方法と、上記3つのモデルの定義を行うだけで、機械学習を行うことができてしまいます。\n",
    "\n",
    "今回、セミナー用のモデル定義は予め実装してあります(`src/doodle.py`ファイル)。\n",
    "\n",
    "コメントなどを含めても150行程度しかありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train_input_fn`、`eval_input_fn`の実装例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, params, is_training=True)\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, params, is_training=False)\n",
    "\n",
    "def _input_fn(data_dir, params, is_training):\n",
    "    # ハイパーパラメータを取得します\n",
    "    # シャッフルのバッファサイズなどをハイパーパラメータとして与えて\n",
    "    # 切り替えられるようにしておくと、コードの修正なしに入力データを調整できます\n",
    "    batch_size  = params.get('batch_size', 96)\n",
    "    buffer_size = params.get('shuffle_buffer_size', 4096)\n",
    "    cmp_type    = params.get('tfrecord_compression_type', 'GZIP')\n",
    "    train_file  = params.get('train_tfrecord_file', 'train.tfr')\n",
    "    test_file   = params.get('test_tfrecord_file', 'test.tfr')\n",
    "\n",
    "    # 学習用データのパス\n",
    "    tfrecord = os.path.join(data_dir, train_file if is_training else test_file)\n",
    "\n",
    "    # TFrecordを読み込み、シャッフルやリピートなどを行います\n",
    "    return (tf.data.TFRecordDataset(tfrecord, compression_type=cmp_type)\n",
    "        .map(_parse_example)\n",
    "        .shuffle(buffer_size)\n",
    "        .batch(batch_size)\n",
    "        .repeat(-1 if is_training else 1) # -1は無限リピートです\n",
    "        .make_one_shot_iterator()\n",
    "        .get_next())\n",
    "\n",
    "# TFRecordをtf.train.Exampleに変換したのでパースする関数です\n",
    "def _parse_example(example):\n",
    "    features = tf.parse_single_example(example,  {\n",
    "        'image': tf.FixedLenFeature([28, 28, 1], tf.float32),\n",
    "        'label': tf.FixedLenFeature([]         , tf.int64),\n",
    "    })\n",
    "    label = features.pop('label')\n",
    "    return features, label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `serving_input_fn`の実装例\n",
    "\n",
    "推論用の入力データ形式の定義を行います。これはAPIサーバにデプロイしない場合も必要なので注意してください。\n",
    "\n",
    "以下では、入力データは、キーを`image`とし、浮動小数型のテンソルであることを定義しています。`[None, 28, 28, 1]`は、データの形状を示しています。\n",
    "\n",
    "TensorFlowで扱われるデータは全てTensor(テンソル)です。この場合、`image`テンソルはランク4のテンソルで、プログラム上では4次元配列で表現されます。各次元の長さは、None(可変長)、28、28、1です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def serving_input_fn(params):\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': tf.placeholder(tf.float32, [None, 28, 28, 1], name='image')\n",
    "    })()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `model_fn`の実装例\n",
    "\n",
    "(一部省略しています)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # ...\n",
    "\n",
    "    # 第一引数のfeaturesが入力データです\n",
    "    image = features['image']\n",
    "\n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # ニューラルネットワークを定義します\n",
    "    #=========================================================\n",
    "    with tf.variable_scope('model', initializer=initializer):\n",
    "        x = image\n",
    "        x = tf.layers.conv2d(x, 32, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2, padding='SAME')\n",
    "        x = tf.layers.conv2d(x, 64, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2, padding='SAME')\n",
    "        x = tf.reshape(x, [-1,7*7*64])\n",
    "        x = tf.layers.dense(x, 1024, activation=tf.nn.relu)\n",
    "        x = tf.layers.dropout(x, rate=dropout_rate, training=is_training)\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        logits = x\n",
    "\n",
    "    # 予測結果: クラスごとの離散確率分布、最も確率の高いクラスのインデクス\n",
    "    predictions = {\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'classes'      : tf.argmax(logits, axis=1),\n",
    "    }\n",
    "    \n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # モデルの誤差を定義します\n",
    "    #=========================================================\n",
    "    with tf.variable_scope('losses'):\n",
    "        # クロスエントロピーを計算して誤差に追加します\n",
    "        cross_entropy_loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels, logits=logits)\n",
    "        \n",
    "        # モデルで追加された全ての誤差の総和を取得します\n",
    "        total_loss = tf.losses.get_total_loss()\n",
    "\n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # モデルを学習(=パラメータを最適化)します\n",
    "    #=========================================================\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.variable_scope('optimizer'), tf.control_dependencies(update_ops):\n",
    "        # total_loss(誤差の総和)が小さくなるようにパラメータを更新します\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        fit = optimizer.minimize(total_loss, global_step)\n",
    "\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークのモデルの定義や学習に関する詳細は、別途ノートブック`model.ipynb`で解説しています。ニューラルネットワークの実装に興味がある方はそちらをご参照ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③Amazon SageMakerでモデルを学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker SDKを使い、ここまでで準備したデータとプログラムを指定して学習を実行します。\n",
    "\n",
    "![](img/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 皆さんの設定を保存する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、データの保存先などの文字列を変数で定義します。ハンズオンでは共用のストレージを利用するため、**各自で保存先など変えて頂くためです**。\n",
    "\n",
    "```python\n",
    "your_name = 'arata-furukawa' # 例\n",
    "```\n",
    "\n",
    "上記のように、`your_name`にご自身の名前やTwitterのIDなど**他の人と被らない文字列**を入れてから、セルを実行してください。(被ると後でエラーになってしまいます。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = '' # 半角英数字とハイフンのみ利用可能です\n",
    "\n",
    "# 文字列チェック\n",
    "import re; assert re.match(r'^[0-9a-z-]+$', your_name) is not None\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "role    = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "bucket  = session.default_bucket()\n",
    "\n",
    "def _s3(path):\n",
    "    return 's3://{}/doodle/model/{}/{}'.format(bucket, your_name, path)\n",
    "data_key_prefix = 'doodle/model/{}/data'.format(your_name)\n",
    "\n",
    "config = dict(\n",
    "    data_dir        = _s3('data'),\n",
    "    output_path     = _s3('export'),\n",
    "    checkpoint_path = _s3('ckpt'),\n",
    "    code_location   = _s3('src'),\n",
    "    public_dir      = _s3('public'),\n",
    "    job_name        = 'doodle-training-job-{}'.format(your_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定した変数を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in six.iteritems(config):\n",
    "    print('key: {:20}, value: {:20}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記で設定したユニークなS3パスに、①で作成したデータセットをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_data_dir = session.upload_data(\n",
    "    'data',                     # ローカルディレクトリ\n",
    "    bucket=bucket,              # アップロードするS3バケット名\n",
    "    key_prefix=data_key_prefix) # アップロードするパスのプリフィクス\n",
    "\n",
    "# 設定と同じ場所になったか確認します\n",
    "assert uploaded_data_dir == config['data_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの学習では、「エスティメータ(Estimator)」を利用します。 エスティメータは、モデルの学習や評価、保存やデプロイなどを行う抽象化されたインターフェイスです。\n",
    "\n",
    "用意したパスなどを設定として渡して、エスティメータを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    # ハイパーパラメータ\n",
    "    # ②で定義したプログラムの各関数の引数に渡されます\n",
    "    # プログラムの挙動を切り替えるのに利用できます\n",
    "    hyperparameters={\n",
    "        'save_summary_steps': 100,\n",
    "        'throttle_secs': 120,\n",
    "    },\n",
    "    \n",
    "    # 先程設定した、各データの保存先のパス\n",
    "    output_path     = config['output_path'],\n",
    "    checkpoint_path = config['checkpoint_path'],\n",
    "    code_location   = config['code_location'],\n",
    "    \n",
    "    # 学習用プログラムに関する設定\n",
    "    source_dir='./src',      # 学習用のプログラムが保存されたローカルディレクトリ\n",
    "    entry_point='doodle.py', # ②で定義した学習用プログラムのファイル名\n",
    "    framework_version='1.6', # 利用したいTensorFlowのバージョン\n",
    "    \n",
    "    # 学習と評価の回数\n",
    "    training_steps=20000,\n",
    "    evaluation_steps=2000,\n",
    "    \n",
    "    # AWSでの実行に関する設定(今回は共用なので変えないでください！)\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge') # ml.p2.xlargeはGPUの搭載されたインスタンスです"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エスティメータに対して、学習用データのパス名を指定して`fit`関数を呼び出すと、学習ジョブが作成され、クラウド上でモデルの学習が実行されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この学習には10〜15分かかります。実行完了までしばらくお待ち下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(config['data_dir'], job_name=config['job_name'],\n",
    "              wait=True, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、`run_tensorboard_locally`引数に`True`を渡すと、ノートブック上でTensorBoardが実行されます。TensorBoardに学習ログを表示するようにしてあるので、下記URLにアクセスして確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://(ノートブックのURL)/`[proxy/6006/](/proxy/6006/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④学習したモデルをダウンロードして、Webアプリに組み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルは、エスティメータの`output_path`引数で指定した場所にGZIP圧縮されたTar書庫で保存されています。中身はTesnorFlow SavedModelと呼ばれるデータ形式です。\n",
    "\n",
    "![](img/5.png)\n",
    "\n",
    "このモデルデータを使えば、Pythonで実行したり、TensorFlow ServingでAPIサーバを構築したり、TensorFlow Liteを使ってAndroidやiOSで実行したりすることが可能です。\n",
    "\n",
    "今回は、TensorFlow.jsを使って、Webブラウザ上でモデルの推論を実行してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをダウンロードして展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = '{}/{}/output/model.tar.gz'.format(config['output_path'], config['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./export ./model.tar.gz\n",
    "!aws s3 cp \"$model_url\" ./model.tar.gz\n",
    "!tar xvzf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow.jsでブラウザ上で実行するために、Web用のフォーマットに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換用ツールをインストールします\n",
    "!pip install tensorflowjs\n",
    "\n",
    "# 変換したモデルの保存先ディレクトリを作成します\n",
    "!mkdir -p ./webapp/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    --output_node_names='probabilities,classes' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    ./export/Servo/* \\\n",
    "    ./webapp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、`./webapp/model`ディレクトリにTensorFlow.jsで実行するためのモデルデータが生成されました！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./webapp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとはTensorFlow.jsで実行するだけです。\n",
    "\n",
    "TensorFlow.js(ES5)では、以下のように実行します。\n",
    "\n",
    "```javascript\n",
    "import {loadFrozenModel} from '@tensorflow/tfjs-converter'\n",
    "\n",
    "// モデルを読み込みます\n",
    "loadFrozenModel(/* tensorflowjs_model.pbのURL */, /* weights_manifest.jsonのURL */)\n",
    "    .then(model => {\n",
    "        // モデルでの推論を実行します\n",
    "        const results = model.execute({\n",
    "            'image_1': /* 画像データ */\n",
    "        })\n",
    "    })\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非常に簡単です！ とはいえ実際にはアプリケーションの「ガワ」を作らねばなりません。その辺りは今回のセミナーの趣旨とは外れますので、今回はWebアプリケーションを事前にご用意いたしました。ダウンロードして展開し、そのアプリケーションで皆さんが作ったモデルデータを読み込んで実行して頂きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./webapp\n",
    "!wget -O webapp.tar.gz https://github.com/maru-labo/doodle/releases/download/v1.0.0/example.tensorflowjs.tar.gz\n",
    "!tar xvzf webapp.tar.gz -C webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、`webapp`ディレクトリ以下にWebアプリケーションに必要なものが揃いました！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、今回使うWebアプリケーションのソースコードは[maru-labo/doodle/examples/tensorflow_js](https://github.com/maru-labo/doodle/tree/master/examples/tensorflow_js)にて公開しています。\n",
    "\n",
    "また、よりシンプルな、TensorFlow.jsを実行する最低限のプログラムサンプルも[maru-labo/doodle/examples/tensorflow_js_simple](https://github.com/maru-labo/doodle/tree/master/examples/tensorflow_js_simple)に公開しています。\n",
    "\n",
    "実際に皆さんが作られたモデルを実行したい場合はぜひ参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤WebアプリをS3でホスティングして公開する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`webapp`ディレクトリに必要なものが揃ったので、Web上に公開してみましょう。S3の静的ホスティング機能を使うと簡単にWebアプリケーションを公開できます。`aws s3 sync`コマンドで`webapp`ディレクトリを`public_dir`変数に格納した皆さんのURLにアップロードします。(※`tensorflowjs_converter`のインストール時にカーネルが再起動されてしまい`config`変数がなくなってしまっていることがあります。その場合は「皆さんの設定を保存する」セルを実行し直してください。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_dir = config['public_dir']\n",
    "!aws s3 sync ./webapp $public_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アップロードされたWebアプリケーションを確認してみましょう！ 下記セルを実行するとURLが表示されますので、別のタブで開いてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://s3-{}.amazonaws.com/{}/index.html'.format(session.boto_region_name, public_dir[5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "- ✔簡単なデータセットを作りました\n",
    "- ✔SageMakerでモデルを学習しました\n",
    "- ✔SageMakerで学習したモデルをWebアプリケーションで実行しました\n",
    "\n",
    "なお、落書き認識モデルについては、本日使用したサンプルを含めて全て[GitHub](https://github.com/maru-labo/doodle)上で公開していますので、より詳しい情報をご希望の方はぜひご参照ください。今後、LiteのサンプルやServingの使い方などもリポジトリに追加する予定です。MITライセンスですので、ご自由にご利用いただけます。お気軽にIssueやPull Requestをお寄せくださいませ。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
